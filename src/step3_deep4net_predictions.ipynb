{"cells":[{"cell_type":"markdown","metadata":{"id":"x_xrvTOoR48y"},"source":["##Setup\n","\n","\n","---\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zIvRHeQlV5rG"},"source":["###Install packages, dependencies, and functions needed\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ucugIzi5RiQW"},"outputs":[],"source":["!apt-get update\n","!apt-get install git\n","\n","# MNE-BIDS preprocessing functions\n","!pip install mne\n","!pip install MNE-bids\n","!pip install -r https://raw.githubusercontent.com/mne-tools/mne-bids-pipeline/main/requirements.txt\n","!git clone https://github.com/mne-tools/mne-bids-pipeline.git /cloned-mne-bids-pipeline\n","\n","!pip install AutoReject\n","!pip install coffeine\n","!pip install Braindecode\n","\n","!git clone https://github.com/meeg-ml-benchmarks/brain-age-benchmark-paper.git /cloned-paper-repo\n","\n","!pip install -U matplotlib\n","\n","!pip install -U scipy\n","!pip install torch torchvision -f https://download.pytorch.org/whl/torch_stable.html\n"]},{"cell_type":"markdown","metadata":{"id":"rT9EfA_NNUbA"},"source":["### Restart Runtime \n","\n","make sure all updated packages are loaded in their newest versions\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TKEKDpaxY5Gi"},"outputs":[],"source":["import torch\n","import os\n","\n","def restart_runtime():\n","  os.kill(os.getpid(), 9)\n","\n","restart_runtime()"]},{"cell_type":"markdown","metadata":{"id":"zAeubOPv-qoM"},"source":["###Mount Google Drive for access to data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21519,"status":"ok","timestamp":1669269905483,"user":{"displayName":"Craig Friedman","userId":"15651282531376911133"},"user_tz":300},"id":"J3Umf3zo-xx2","outputId":"060f48be-05d3-4ff7-c871-3782ce6127fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oqBIIr6DJhys"},"outputs":[],"source":["######################################################################################################\n","#  ________   _________   ___    ___ ___  ___  ________  ________  ___  __      _______   _______\n","# |\\   ___  \\|\\___   ___\\|\\  \\  /  /|\\  \\|\\  \\|\\   __  \\|\\   ____\\|\\  \\|\\  \\   /  ___  \\ /  ___  \\\n","# \\ \\  \\\\ \\  \\|___ \\  \\_|\\ \\  \\/  / | \\  \\\\\\  \\ \\  \\|\\  \\ \\  \\___|\\ \\  \\/  /|_/__/|_/  //__/|_/  /|\n","#  \\ \\  \\\\ \\  \\   \\ \\  \\  \\ \\    / / \\ \\   __  \\ \\   __  \\ \\  \\    \\ \\   ___  \\__|//  / /__|//  / /\n","#   \\ \\  \\\\ \\  \\   \\ \\  \\  /     \\/   \\ \\  \\ \\  \\ \\  \\ \\  \\ \\  \\____\\ \\  \\\\ \\  \\  /  /_/__  /  /_/__\n","#    \\ \\__\\\\ \\__\\   \\ \\__\\/  /\\   \\    \\ \\__\\ \\__\\ \\__\\ \\__\\ \\_______\\ \\__\\\\ \\__\\|\\________\\\\________\\\n","#     \\|__| \\|__|    \\|__/__/ /\\ __\\    \\|__|\\|__|\\|__|\\|__|\\|_______|\\|__| \\|__| \\|_______|\\|_______|\n","#                        |__|/ \\|__|\n","######################################################################################################\n","\n","import mne\n","import numpy as np\n","import pandas as pd\n","import sklearn\n","from sklearn.pipeline import make_pipeline\n","from mne.decoding import Vectorizer\n","from sklearn.decomposition import PCA\n","from sklearn.linear_model import Ridge\n"]},{"cell_type":"markdown","metadata":{"id":"sxM1Zda9M15M"},"source":["# 250hz Autorejected data?\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nppRp6UmM3a1"},"outputs":[],"source":["import pickle\n","%cd /content/drive/My Drive/brainAge_competition/\n","with open(r\"22chans_250hz_2secEpochs_autoreject.sav\", \"rb\") as input_file:\n","  epoched_data = pickle.load(input_file)\n","\n","# get the age to predict from the CSV file\n","train_path = \"/content/drive/My Drive/brainAge_competition/raws/\"\n","train_subj = 1200\n","meta = pd.read_csv(train_path + \"train_subjects.csv\")\n","y_train = []\n","for age in meta[\"age\"][:train_subj]:\n","    y_train.append(age)\n","y_trainSet = y_train\n"]},{"cell_type":"markdown","source":["# y's added to epoched data"],"metadata":{"id":"xr2Tsr5eXG43"}},{"cell_type":"code","source":["from numpy.matlib import repmat\n","from braindecode.datasets import WindowsDataset, BaseConcatDataset\n","\n","for i in range(0,1200,1):\n","  print(i)\n","  current_y = np.matlib.repmat(y_trainSet[i],m=len(epoched_data[i]), n=1)\n","  metadata = np.array([\n","      list(range(len(epoched_data[i]))),  # i_window_in_trial (chunk of rec)\n","      len(epoched_data[i]) * [-1],  # i_start_in_trial (unknown / unused)\n","      len(epoched_data[i]) * [-1],  # i_stop_in_trial (unknown / unused\n","      current_y[:,0],  # target (e.g. subject age)\n","  ])\n","  metadata = pd.DataFrame(\n","      data=metadata.T,\n","      columns=['i_window_in_trial', 'i_start_in_trial', 'i_stop_in_trial',\n","                'target'],)\n","  epoched_data[i].metadata = metadata\n","\n","for i in range(0,1200,1):\n","  print(epoched_data[i].metadata)\n","\n","datasets = []\n","for i in range(0,1200,1):\n","  ds = WindowsDataset(\n","      windows=epoched_data[i],\n","      #description=description,\n","      targets_from='metadata',\n","      transform=None,\n","  )\n","  datasets.append(ds)\n","\n","fullds = BaseConcatDataset(datasets)\n","fullds"],"metadata":{"id":"E_Yzb3tUEc68"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iIs119O1YxVT"},"source":["# set-up analysis type + separate into train, valid, and test subsets\n","\n","### this attempt built on code from Banville, H., Wood, S. U., Aimone, C., Engemann, D. A., & Gramfort, A. (2022). Robust learning from corrupted EEG with dynamic spatial filtering. NeuroImage, 251, 118994."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BBU0sV5ot5KE"},"outputs":[],"source":["import os\n","import argparse\n","\n","import mne\n","import torch\n","from torch import nn\n","from braindecode import EEGClassifier\n","from braindecode.models import SleepStagerChambon2018\n","from braindecode.util import set_random_seeds\n","from skorch.helper import predefined_split\n","from skorch.callbacks import (\n","    Checkpoint, EarlyStopping, EpochScoring, LRScheduler)\n","from sklearn.metrics import (\n","    confusion_matrix, classification_report, balanced_accuracy_score)\n","from sklearn.utils.class_weight import compute_class_weight\n","import pickle\n","\n","%cd /cloned-paper-repo\n","from deep_learning_utils import (\n","    create_dataset, create_model, create_estimator)\n","\n","model_name = 'deep'\n","cropped = True\n","seed = 20211022\n","\n","\n","import os\n","%cd '/content/drive/MyDrive/dynamic_spatial_filtering/cloned-DSF-git'\n","\n","save_dir=\"/content/drive/My Drive/brainAge_competition/DSFattempt2/\"\n","\n","denoising='no_denoising'\n","#denoising='autoreject'\n","#denoising='data_augm'\n","\n","dsf_type = 'vanilla'\n","#dsf_type = 'dsfd'\n","#dsf_type = 'dsfm_st'\n","\n","def get_exp_name(dsf_type, denoising):\n","    return f'{dsf_type}-{denoising}'\n","\n","dir_name = get_exp_name(dsf_type, denoising)\n","import os\n","save_path = os.path.join(save_dir, dir_name)\n","if not os.path.exists(save_path):\n","    os.makedirs(save_path)\n","\n","dsf_n_out_channels=None\n","\n","!pip install -r requirements.txt\n","\n","\n","%cd '/content/drive/MyDrive/dynamic_spatial_filtering/cloned-DSF-git'\n","%ls\n","!pip install -r requirements.txt\n","\n","from transforms import Compose, AdditiveWhiteNoise, logm_cov\n","from models import DynamicSpatialFilter\n","from utils import (\n","    load_data, apply_autoreject, split_dataset, none_or_int, get_exp_name,\n","    seed_np_rng)\n","\n","seed = 20211022\n","\n","if denoising == 'autoreject':\n","    windows_dataset = apply_autoreject(windows_dataset, seed, n_jobs)\n","\n","# Split into train, valid and test sets\n","valid_size=0.2\n","test_size=0.2\n","random_state_valid=seed\n","random_state_test=seed\n","\n","train_set, valid_set, test_set = split_dataset(\n","    fullds, valid_size, test_size,\n","    random_state_valid=random_state_valid,\n","    random_state_test=random_state_test)\n"]},{"cell_type":"markdown","metadata":{"id":"o4W0MqmyZHYd"},"source":["# Add data transform if data_augm is being used"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PZgRkmVpY80e"},"outputs":[],"source":["import copy\n","\n","import mne\n","import numpy as np\n","from autoreject import AutoReject\n","from autoreject.autoreject import _check_data, _apply_interp, _apply_drop\n","from sklearn.utils import check_random_state\n","\n","class anthonyMod_AdditiveWhiteNoise(object):\n","    \"\"\"Additive white noise.\n","    Parameters\n","    ----------\n","    p : float\n","        Probability that a channel receives white noise [0, 1].\n","    noise_strength : float | tuple\n","        Relative strength of the noise. The output of this transform is a\n","        convex combination of the original signal x and white noise n:\n","            y = (1 - w) * x + w * n\n","        If provided as a tuple (min_strength,max_strength), the relative\n","        strength will be uniformly sampled in the provided open interval.\n","    noise_std : float | tuple | None\n","        Standard deviation of the white noise. If provided as a tuple (min_std,\n","        max_std), the standard deviation will be uniformly sampled in the\n","        provided open interval. If None, the standard deviation will be the\n","        same as the standard deviation of the input signal.\n","    random_state : 'global' | np.random.RandomState | int | None\n","        Random state used to control noise parameters (channels to be\n","        corrupted, strength and standard deviation of noise). If 'global',\n","        random numbers will be generated with the `np.random` module so they\n","        use the global seed (this is useful to avoid duplicate augmentations\n","        when using transforms with num_workers > 1).\n","    noise_random_state : 'global' | np.random.RandomState | int | None\n","        Random state used to generate the white noise itself. If None, the\n","        random number generator will be initialized to the same as\n","        `random_state`'s. If 'global', random numbers will be generated with\n","        the `np.random` module so they use the global seed (this is useful to\n","        avoid duplicate augmentations when using transforms with\n","        num_workers > 1).\n","        NOTE: The two random states are kept separate so that it is possible to\n","              have identical recording-wise corruption on raw data and epoched\n","              data.\n","    recording_wise : bool\n","        If True and a 3D array (n_windows, n_channels, n_times) is passed to\n","        __call__, the same noise parameters will be used to generate the noise\n","        of all windows. If False, each window will be corupted with its own\n","        noise parameters.\n","    \"\"\"\n","    __name__ = 'AdditiveWhiteNoise'\n","\n","    def __init__(self, p, noise_strength, noise_std=None,\n","                 random_state='global', noise_random_state=None,\n","                 recording_wise=True):\n","        self.p = p\n","        self.noise_strength = noise_strength\n","        self.noise_std = noise_std\n","        self._set_random_states(random_state, noise_random_state)\n","        self.recording_wise = recording_wise\n","        print(\"Data Augmentation Is ON\")   \n","\n","    def _set_random_states(self, random_state, noise_random_state):\n","        if random_state == 'global':\n","            self.rng = np.random\n","        else:\n","            self.rng = check_random_state(random_state)\n","\n","        if noise_random_state == 'global':\n","            self.noise_rng = np.random\n","        elif noise_random_state is None:\n","            if random_state == 'global':\n","                self.noise_rng = np.random\n","            else:\n","                self.noise_rng = copy.deepcopy(self.rng)\n","        else:\n","            self.noise_rng = check_random_state(noise_random_state)\n","\n","    def __call__(self, X, mask=None):\n","        \"\"\"Generate and apply white noise to an mne.Epochs object.\n","        Parameters\n","        ----------\n","        X : np.ndarray | mne.Epochs\n","            Data to be corrupted.\n","        mask : np.ndarray | None\n","            If provided as a numpy array of bool with shape (n_channels,), will\n","            replace the mask that is normally sampled at every call.\n","        Returns\n","        -------\n","        np.ndarray :\n","            Corrupted data.\n","        \"\"\"\n","        #print(\"Data Augmentation Is ON\")        \n","        X_out = X._data if isinstance(X, mne.Epochs) else X\n","\n","        if X_out.ndim == 2:\n","            n_channels, n_times = X_out.shape\n","        elif X_out.ndim == 3:\n","            if not self.recording_wise:\n","                all_Xi = [self.__call__(Xi, mask) for Xi in X_out]\n","                return np.stack(all_Xi, axis=0)\n","            n_windows, n_channels, n_times = X_out.shape\n","        else:\n","            raise ValueError(\n","                f'Data must have 2 or 3 dimensions, got {X_out.ndim}')\n","\n","        # Pick channels\n","        if mask is None:\n","            mask = self.rng.binomial(1, self.p, n_channels) == 1\n","        n_bad_chs = sum(mask)\n","\n","        if n_bad_chs > 0:\n","            if isinstance(self.noise_std, (int, float)):\n","                loc = 0\n","                scale = self.noise_std\n","            elif isinstance(self.noise_std, tuple):\n","                loc = np.zeros(n_bad_chs)\n","                scale = self.rng.uniform(\n","                    low=self.noise_std[0], high=self.noise_std[1],\n","                    size=n_bad_chs)\n","            elif self.noise_std is None:\n","                loc = np.zeros(n_bad_chs)\n","                scale = X[mask].std(axis=1)\n","            else:\n","                raise ValueError(\n","                    'noise_std must be an int, float, tuple or None, got '\n","                    f'{type(self.noise_std)}.')\n","\n","            if X_out.ndim == 2:\n","                n = self.noise_rng.normal(\n","                    loc=loc, scale=scale, size=(n_times, n_bad_chs)).T\n","            elif X_out.ndim == 3:\n","                n = self.noise_rng.normal(\n","                    loc=loc, scale=scale, size=(n_windows, n_times, n_bad_chs))\n","                n = np.transpose(n, (0, 2, 1))\n","\n","            if isinstance(self.noise_strength, tuple):\n","                w = self.rng.uniform(\n","                    low=self.noise_strength[0], high=self.noise_strength[1])\n","            else:\n","                w = self.noise_strength\n","\n","            if X_out.ndim == 2:\n","                X_out[mask] = (1 - w) * X_out[mask] + w * n\n","            elif X_out.ndim == 3:\n","                X_out[:, mask] = (1 - w) * X_out[:, mask] + w * n\n","\n","        return X_out\n","\n","if denoising == 'data_augm':\n","    train_set.transform = anthonyMod_AdditiveWhiteNoise(\n","        p=0.5, noise_strength=(0.5, 1), noise_std=(20, 50),\n","        recording_wise=False)\n","    \n","#train_set.transform\n"]},{"cell_type":"markdown","source":["# Continued set-up"],"metadata":{"id":"gQpBLzZaYVEp"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":303,"status":"ok","timestamp":1669270186917,"user":{"displayName":"Craig Friedman","userId":"15651282531376911133"},"user_tz":300},"id":"65fnVLD5ZLim","outputId":"abd9512a-cb7c-4583-bc21-5b9a876a2e7e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 9.9367018e-05,  9.3538067e-05,  8.9370544e-05, ...,\n","         4.0873133e-06,  1.9670015e-06,  4.7957252e-07],\n","       [ 8.8532397e-05,  8.5109525e-05,  8.1272403e-05, ...,\n","         1.4493757e-05,  1.4379733e-05,  1.2860188e-05],\n","       [ 1.0450727e-04,  9.9104902e-05,  9.5193347e-05, ...,\n","         1.0827463e-05,  7.6711913e-06,  5.2751857e-06],\n","       ...,\n","       [-1.4357081e-05, -1.6948701e-05, -1.9407458e-05, ...,\n","        -3.9371651e-05, -4.0957515e-05, -3.9101462e-05],\n","       [ 2.3919374e-05,  1.7511162e-05,  1.4188075e-05, ...,\n","        -3.0115942e-05, -3.1787542e-05, -3.1874457e-05],\n","       [ 5.8286274e-05,  5.2283671e-05,  4.7506655e-05, ...,\n","        -1.7269940e-05, -1.8794333e-05, -1.9226192e-05]], dtype=float32)"]},"metadata":{},"execution_count":11}],"source":["\n","\n","n_epochs = 40\n","batch_size = 128 #128 #if dataset == 'camcan' else 256\n","cropped = True\n","\n","import torch\n","cuda = torch.cuda.is_available() \n","\n","torch.backends.cudnn.enabled = True\n","torch.backends.cudnn.benchmark = False # not sure / dsf paper had this as false I think / #not args.deterministic\n","torch.backends.cudnn.deterministic = True # args.deterministic\n","# Set random seed to be able to roughly reproduce results\n","# Note that with cudnn benchmark set to True, GPU indeterminism\n","# may still make results substantially different between runs.\n","# To obtain more consistent results at the cost of increased computation time,\n","# you can set `cudnn_benchmark=False` in `set_random_seeds`\n","# or remove `torch.backends.cudnn.benchmark = True`\n","set_random_seeds(seed=seed, cuda=cuda)\n","\n","################################################################################################\n","# age regression pipleine code\n","\n","from deep_learning_utils import ( create_model,\n","    create_estimator)\n","\n","x, y, _ = train_set[0]\n","\n","n_channels, window_size = x.shape\n","\n","y\n","n_channels\n","window_size\n","\n","\n","x"]},{"cell_type":"markdown","source":["# Create model"],"metadata":{"id":"0l_SiNtZYhJ-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"X-J6K6UiW-EF"},"outputs":[],"source":["\n","###############################################################################################\n","# our output has 3 dimensions, probably b/c we didn't do the X = slice dataset step\n","\n","#def anthonyMod_squeeze_to_ch_x_classes(x):\n","#    \"\"\"Squeeze the model output from any dimension to batch_size x n_classes.\"\"\"\n","#    while x.size()[-1] == 1 and x.ndim > 2:\n","#        print(x.shape)\n","#        x = x.squeeze(x.ndim-1)\n","#    return x\n","\n","def anthonyMod_squeeze_to_ch_x_classes(x):\n","    \"\"\"Squeeze the model output from any dimension to batch_size x n_classes.\"\"\"\n","    while x.size()[-1] == 1 and x.ndim >= 2:\n","        x = x.squeeze(x.ndim-1)\n","    return x\n","\n","import mne\n","import torch\n","from torch import nn\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import mean_absolute_error, r2_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.compose import TransformedTargetRegressor\n","from joblib.parallel import Parallel, delayed\n","\n","from mne_bids import BIDSPath\n","\n","from skorch.callbacks import LRScheduler, BatchScoring\n","from skorch.helper import SliceDataset\n","\n","from braindecode.datasets import WindowsDataset, BaseConcatDataset\n","from braindecode.util import set_random_seeds\n","from braindecode.models import ShallowFBCSPNet, Deep4Net\n","from braindecode.models.util import to_dense_prediction_model\n","from braindecode.models.modules import Expression\n","from braindecode import EEGRegressor\n","\n","def create_model_v2(model_name, window_size, n_channels, cropped, seed):\n","    \"\"\"Create a braindecode model (either ShallowFBCSPNet or Deep4Net).\n","    Parameters\n","    ----------\n","    model_name: str\n","        The name of the model (either 'shallow' or 'deep').\n","    window_size: int\n","        The length of the input data time series in samples.\n","    n_channels: int\n","        The number of input data channels.\n","    cropped: bool\n","        A flag to switch between cropped and trialwise decoding.\n","    seed: int\n","        The seed to be used to initialize the network.\n","    Returns\n","    -------\n","    model: braindecode.models.Deep4Net or braindecode.models.ShallowFBCSPNet\n","        A braindecode convolutional neural network.\n","    lr: float\n","        The learning rate to be used in network training.\n","    weight_decay: float\n","        The weight decay to be used in network training.\n","    \"\"\"\n","    # check if GPU is available, if True chooses to use it\n","    cuda = torch.cuda.is_available()\n","    if cuda:\n","        torch.backends.cudnn.benchmark = True\n","    # Set random seed to be able to reproduce results\n","    set_random_seeds(seed=seed, cuda=cuda)\n","\n","    final_conv_length = 'auto'\n","    if model_name == 'shallow':\n","        if cropped:\n","            window_size = None\n","            final_conv_length = 35\n","        model = ShallowFBCSPNet(\n","            in_chans=n_channels,\n","            n_classes=1,\n","            input_window_samples=window_size,\n","            final_conv_length=final_conv_length,\n","        )\n","        lr = 0.0625 * 0.01 \n","        weight_decay = 0\n","    elif model_name == 'deep':\n","        if cropped:\n","            window_size = None\n","            final_conv_length = 1\n","        model = Deep4Net(\n","            in_chans=n_channels,\n","            n_classes=1,\n","            input_window_samples=window_size,\n","            final_conv_length=final_conv_length,\n","            stride_before_pool=True,\n","        )\n","        lr = 1 * 0.01\n","        weight_decay = 0.5 * 0.001\n","    else:\n","        raise ValueError(f'Model {model_name} unknown.')\n","\n","    if cropped:\n","        to_dense_prediction_model(model)\n","\n","    # remove the softmax layer from models\n","    new_model = torch.nn.Sequential()\n","    for name, module_ in model.named_children():\n","        if \"softmax\" in name:\n","            continue\n","        new_model.add_module(name, module_)\n","\n","    if cropped:\n","        new_model.add_module('global_pool', torch.nn.AdaptiveAvgPool1d(1))\n","        new_model.add_module('squeeze2', Expression(anthonyMod_squeeze_to_ch_x_classes))\n","    model = new_model\n","\n","    # Send model to GPU\n","    if cuda:\n","        model.cuda()\n","        n_devices = torch.cuda.device_count()\n","        if n_devices > 1:\n","            print(f'Using {n_devices} GPUs.')\n","            model = nn.DataParallel(model)\n","\n","    return model, lr, weight_decay\n","\n","\n","################################# dsf pt 1/2 #############################################\n","\n","import torch\n","from torch import nn\n","\n","def soft_thresholding(x, b, a=None):\n","    \"\"\"Remap values between [-a, b] to 0, keep the rest linear.\n","    \"\"\"\n","    if a is None:\n","        a = b\n","    return (torch.clamp(x - b, min=0) * (x > 0) +\n","            torch.clamp(x + a, max=0) * (x <= 0))\n","\n","def logm_eig(A, spd=True):\n","    \"\"\"Batched matrix logarithm through eigenvalue decomposition.\n","\n","    Parameters\n","    ----------\n","    A : torch.Tensor\n","        Square matrices of shape (B, F, C, T).\n","\n","    Returns\n","    -------\n","    torch.Tensor :\n","        Matrix logarithm of A.\n","    \"\"\"\n","    e, v = torch.symeig(A, eigenvectors=True)\n","    e = torch.clamp(e, min=1e-10)  # clamp the eigenvalues to avoid -inf\n","    return v @ torch.diag_embed(\n","        torch.log(e), dim1=2, dim2=3) @ v.transpose(2, 3)\n","\n","class SpatialFeatureExtractor(nn.Module):\n","    \"\"\"Extract spatial features from input.\n","    \"\"\"\n","    def __init__(self, kind, n_channels):\n","        super().__init__()\n","        self.kind = kind\n","        self.n_channels = n_channels\n","        self.inds = torch.triu_indices(n_channels, n_channels)\n","\n","    @staticmethod\n","    def _cov(x):\n","        xm = x - x.mean(axis=3, keepdims=True)\n","        return xm @ xm.transpose(2, 3) / (x.shape[3] - 1)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        x.shape = (B, F, C, T)\n","        \"\"\"\n","        if self.kind == 'log_diag_cov':\n","            out = torch.log(torch.var(x, 3, unbiased=True))\n","            out[torch.isneginf(out)] = 0\n","        elif self.kind == 'logm_cov_eig':\n","            cov = self._cov(x)\n","            logm_cov = logm_eig(cov)\n","            out = logm_cov[:, :, self.inds[0], self.inds[1]]\n","        else:\n","            out = None\n","\n","        return out\n","\n","    @property\n","    def n_outputs(self):\n","        if self.kind == 'log_diag_cov':\n","            return self.n_channels\n","        else:\n","            return int(self.n_channels * (self.n_channels + 1) / 2)\n","\n","class AnthonyMod_DynamicSpatialFilter(nn.Module):\n","    \"\"\"Dynamic spatial filter module.\n","\n","    Input: (B, F, C, T) [F is the number of filters]\n","    Output: (B, F, C', T) [transformed input]\n","\n","    Parameters\n","    ----------\n","    n_channels : int\n","        Number of input channel.\n","    mlp_input : str\n","        What to feed the MLP. See SpatialFeatureExtractor.\n","    n_hidden : int | None\n","        Number of hidden neurons in the MLP. If None, use `ratio`.\n","    ratio : float\n","        If `n_hidden` is None, the number of hidden neurons in the MLP is\n","        computed as int(ratio * n_inputs).\n","    n_out_channels : int | None\n","        Number of output (\"virtual\") channels in the DSF-based models (only\n","        affects DSF models). If None, n_out_channels = n_channels.\n","    apply_soft_thresholding : bool\n","        If True, apply soft thresholding to the spatial filter matrix W.\n","    return_att : bool\n","        If True, `forward()` returns attention values as well. Used for\n","        inspecting the model.\n","    \"\"\"\n","    def __init__(self, n_channels, mlp_input='log_diag_cov', n_hidden=None,\n","                 ratio=1, n_out_channels=None, apply_soft_thresh=False,\n","                 return_att=False):\n","        super().__init__()\n","        self.apply_soft_thresh = apply_soft_thresh\n","        self.return_att = return_att\n","\n","        # Initialize spatial feature extractor\n","        self.feat_extractor = SpatialFeatureExtractor(\n","            mlp_input, n_channels)\n","        n_inputs = self.feat_extractor.n_outputs\n","        if n_hidden is None:\n","            n_hidden = int(ratio * n_inputs)\n","\n","        # Define number of outputs\n","        if n_out_channels is None:\n","            n_out_channels = n_channels\n","        self.n_out_channels = n_out_channels\n","        n_outputs = n_out_channels * (n_channels + 1)\n","\n","        self.mlp = nn.Sequential(\n","            nn.Linear(n_inputs, n_hidden),\n","            nn.ReLU(),\n","            nn.Linear(n_hidden, n_outputs)\n","        )\n","        print(\"DSF is ON\")\n","\n","    def forward(self, x):\n","        if isinstance(x, list):  # logm was computed on CPU with transforms\n","            x, feats = x\n","            feats = feats.unsqueeze(1)\n","        else:\n","            feats = None\n","        if x.ndim == 3:\n","            b, c, _ = x.shape\n","            f = 1\n","            x = x.unsqueeze(1)\n","        elif x.ndim == 4:\n","            b, f, c, _ = x.shape\n","\n","        mlp_out = self.mlp(self.feat_extractor(x) if feats is None else feats)\n","\n","        W = mlp_out[:, :, self.n_out_channels:].view(\n","            b, f, self.n_out_channels, c)\n","        if self.apply_soft_thresh:\n","            W = soft_thresholding(W, 0.1)\n","        bias = mlp_out[:, :, :self.n_out_channels].view(\n","            b, f, self.n_out_channels, 1)\n","        out = W @ x + bias\n","        out = torch.squeeze(out,1) # squeeze second dim\n","        if self.return_att:\n","            return out, (W, bias)\n","        else:\n","            return out\n","\n","##########################\n","\n","if dsf_type != 'vanilla':\n","    if dsf_type == 'dsfd':\n","        mlp_input = 'log_diag_cov'\n","        dsf_soft_thresh = False\n","    elif dsf_type == 'dsfm_st':\n","        mlp_input = 'logm_cov_eig'\n","        dsf_soft_thresh = True\n","\n","        # Use CPU to compute logm, it's faster than pytorch with cuda\n","        train_set.transform = logm_cov if train_set.transform[0] is None \\\n","            else Compose([train_set.transform[0], logm_cov])\n","        valid_set.transform = logm_cov\n","        test_set.transform = logm_cov\n","\n","    else:\n","        raise ValueError(\n","            f'dsf_type must be None, dsfd or dsfm_st, got {dsf_type}')\n","    dsf = AnthonyMod_DynamicSpatialFilter(\n","        n_channels, mlp_input=mlp_input,\n","        n_out_channels=dsf_n_out_channels,\n","        apply_soft_thresh=dsf_soft_thresh)\n","    n_channels = dsf.n_out_channels\n","\n","\n","\n","\n","##################################################################################\n","\n","\n","model_name='deep'\n","\n","model, lr, weight_decay = create_model_v2(\n","    model_name=model_name,\n","    window_size=window_size,\n","    n_channels=n_channels,\n","    cropped=True,\n","    seed=seed,\n",")\n","\n","model\n","\n","################################# dsf pt 2/2 #############################################\n","\n","if dsf_type != 'vanilla':\n","    model = nn.Sequential(dsf, model)\n","  \n","n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(f'\\nModel has {n_params} trainable parameters.\\n')\n","\n","if torch.cuda.device_count() > 1:  # Parallelize model over GPUs\n","    print(f'\\nUsing {torch.cuda.device_count()} GPUs.\\n')\n","    model = nn.DataParallel(model)\n","\n","##################################################################################\n","print(lr)"]},{"cell_type":"markdown","source":["# Wrap model in estimator + more set-up"],"metadata":{"id":"ZHQTEgN4Yjon"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4fln0GfKeC0d"},"outputs":[],"source":["n_jobs=1\n","from skorch.callbacks import LRScheduler, BatchScoring\n","\n","# incorporate checkpoint so we can get the optimal params\n","from skorch.callbacks import (\n","    Checkpoint, EarlyStopping, EpochScoring, LRScheduler)\n","\n","num_workers=1\n","\n","cp = Checkpoint(dirname=save_path)\n","#patience= 7 # with such small ptps let's use full epochs  # dsf paper used 7 # default is 5\n","#early_stopping = EarlyStopping(patience=patience)\n","\n","callbacks = [\n","    # can be dropped if there is no interest in progress of _window_ r2\n","    # during training\n","    (\"R2\", BatchScoring('r2', lower_is_better=False, on_train=True)),\n","    # can be dropped if there is no interest in progress of _window_ mae\n","    # during training\n","    (\"MAE\", BatchScoring(\"neg_mean_absolute_error\",\n","                          lower_is_better=False, on_train=True)),\n","    (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n","    (\"cp\",cp),\n","    #('patience', early_stopping)\n","]\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","if device == 'cuda':\n","    # Too many workers can create an IO bottleneck - n_gpus * 5 is a good\n","    # rule of thumb\n","    max_num_workers = torch.cuda.device_count() * 5\n","    num_workers = min(max_num_workers, n_jobs if n_jobs > 1 else 0)\n","else:\n","    num_workers = n_jobs if n_jobs > 1 else 0\n","\n","from braindecode import EEGRegressor\n","\n","model.pool_4.dilation = (31,1) # since using 2 sec epochs instead of 10 sec epochs\n","\n","estimator = EEGRegressor(\n","    model,\n","    criterion=torch.nn.L1Loss,  # optimize MAE\n","    optimizer=torch.optim.AdamW,\n","    optimizer__lr=lr,\n","    optimizer__weight_decay=weight_decay,\n","    max_epochs=n_epochs,\n","    train_split=predefined_split(valid_set), #train_split=None,  # we do splitting via KFold object in cross_validate\n","    batch_size=batch_size,\n","    callbacks=callbacks,\n","    device=device,\n","    iterator_train__num_workers=num_workers,\n","    iterator_valid__num_workers=num_workers,\n","    iterator_train__shuffle=True,\n","    iterator_train__worker_init_fn=seed_np_rng\n",")\n","\n","\n","estimator\n","\n"]},{"cell_type":"markdown","source":["# Fit and evaluate model"],"metadata":{"id":"OdXZ4A5mY-rn"}},{"cell_type":"code","source":["\n","mne.set_log_level('ERROR')\n","estimator\n","estimator.fit(train_set, y=None)\n","\n","# need to modify neural net since we using 2 sec data instead of 10 sec data\n","\n","#    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\\\n","# Given input size: (200x63x1). Calculated output size: (200x-99x1). Output size is too small\n","\n","# i think it's at pool_4\n","# should we just go to 10 sec @ 200hz for 2001 samples per epoch to avoid this for now? \n","# pool_4 dialtion from 81,1 to 21,1 and yup running, 31,1 got better performance on quick comparison so using\n","\n","import gc\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","# Load best model\n","estimator.initialize()\n","estimator.load_params(checkpoint=cp)\n","save_path = '/content/drive/My Drive/brainAge_competition/DSFattempt2/vanilla-no_denoising'\n","\n","\n","# Pickle best model\n","with open(os.path.join(save_path, 'best_model.pkl'), 'wb') as f:\n","    estimator.train_split = None  # Avoid pickling the validation set\n","    pickle.dump(estimator, f)\n","\n","#%% 5- Evaluate performance\n","len(test_set)\n","test_set[0][1]\n","\n","y_true_test=[]\n","for i in range(0,len(test_set),1):\n","  y_true_test.append(test_set[i][1])\n","\n","y_true_test = np.array(y_true_test)\n","y_true_test.shape\n","\n","#y_true_test = test_set.get_metadata()['target'].to_numpy()\n","y_pred_test = estimator.predict(test_set)\n","\n","x=y_pred_test\n","y=y_true_test\n","\n","from sklearn.metrics import r2_score, mean_absolute_error\n","MAE=mean_absolute_error(y_true_test, y_pred_test)\n","rsq=r2_score(y_true_test, y_pred_test)\n","\n","print(f'MAE = {MAE} and r^2 = {rsq}')"],"metadata":{"id":"2ey6bHpmZABn"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1xQJ29QOIV4UjgggfzVU01RBJ0GC7cSQN","timestamp":1656006659849},{"file_id":"1MtQdW0A2A8_RZXsrD8GabqiAEj4Njw33","timestamp":1654620829552},{"file_id":"1uD-v1kZAgbkCmknRYpU342wE1PnWOboU","timestamp":1648586218423},{"file_id":"1vd8uX4yzxsbC0LTWU5xP3an9j0jtEzoG","timestamp":1648443526464}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}
